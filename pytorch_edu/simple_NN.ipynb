{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 50)\n",
    "        self.out = nn.Linear(50, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        out = F.softmax(self.out(x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "num_epoch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_train = datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor())\n",
    "load_test = datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train = DataLoader(load_train, batch_size, shuffle=True)\n",
    "test = DataLoader(load_test, batch_size, shuffle=True)\n",
    "\n",
    "data, label = load_test[23]\n",
    "print(label)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]/tmp/ipykernel_31212/1115388479.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(self.out(x))\n",
      "100%|██████████| 938/938 [00:10<00:00, 87.07it/s]\n",
      "100%|██████████| 938/938 [00:10<00:00, 86.43it/s]\n",
      "100%|██████████| 938/938 [00:10<00:00, 86.42it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = NN(input_size, num_classes).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for batch_idx, (data, label) in enumerate(tqdm(train)):\n",
    "        \n",
    "        data = data.to(device=device)\n",
    "        label = label.to(device=device)\n",
    "\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "        y = model(data)\n",
    "        loss = criterion(y, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(data, model):\n",
    "    \n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, label in data:\n",
    "\n",
    "            x = x.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            y = model(x)\n",
    "\n",
    "            _, predictions = y.max(1)\n",
    "\n",
    "            num_correct += (predictions == label).sum()\n",
    "            num_samples += predictions.shape[0]\n",
    "\n",
    "    accuracy = num_correct / num_samples * 100\n",
    "    print(float(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31212/1115388479.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(self.out(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0199966430664\n",
      "95.72166442871094\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test, model)\n",
    "check_accuracy(train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe0011ce67a31b72ba55fb8e7bb9d2ac2b6ebade09aef517c89167728047b0fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
